{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ofsJK5CHODEI","executionInfo":{"status":"ok","timestamp":1710697068994,"user_tz":-60,"elapsed":23625,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}},"outputId":"7869a4bc-efa1-40b4-b952-3a7c90c71b92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: transformer_lens in /usr/local/lib/python3.10/dist-packages (1.14.0)\n","Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.28.0)\n","Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.14.1)\n","Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n","Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.18.0)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.7.0)\n","Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n","Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.28)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.25.2)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.7.1)\n","Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.1.2)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.2)\n","Requirement already satisfied: transformers>=4.34 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.38.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.10.0)\n","Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.16.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.9.3)\n","Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2023.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.16.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.105)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.4.99)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->transformer_lens) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->transformer_lens) (0.15.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.42)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.42.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.3.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n","Requirement already satisfied: circuitsvis in /usr/local/lib/python3.10/dist-packages (1.43.2)\n","Requirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (7.0.2)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (1.25.2)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.3.1)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.9.2.26)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->circuitsvis) (12.4.99)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.1.0->circuitsvis) (3.13.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (2023.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->circuitsvis) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->circuitsvis) (1.3.0)\n"]}],"source":["!pip install einops\n","!pip install transformer_lens\n","!pip install circuitsvis"]},{"cell_type":"code","source":["# This cell makes sure modules are auto-loaded when you change external python files\n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"3SzbMYpOYf1n","executionInfo":{"status":"ok","timestamp":1710697068995,"user_tz":-60,"elapsed":26,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# If you are working in Colab, then consider mounting your assignment folder to your drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aBmCrDdYlAX","executionInfo":{"status":"ok","timestamp":1710697071688,"user_tz":-60,"elapsed":2716,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}},"outputId":"5ec29cd7-9382-475e-98a9-1762839e577a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# and change the path below to point to the assignment folder\n","%cd /content/drive/MyDrive/Colab Notebooks/Mechinterp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chIZlRFWYw6e","executionInfo":{"status":"ok","timestamp":1710697071689,"user_tz":-60,"elapsed":19,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}},"outputId":"e4282091-cb15-41a1-f57a-d09e34081a09"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Mechinterp\n"]}]},{"cell_type":"code","source":["import os; os.environ['ACCELERATE_DISABLE_RICH'] = \"1\"\n","import sys\n","import einops\n","from dataclasses import dataclass\n","from transformer_lens import HookedTransformer\n","from transformer_lens.utils import gelu_new, tokenize_and_concatenate\n","import torch as t\n","from torch import Tensor\n","import torch.nn as nn\n","import numpy as np\n","import torch.optim as optim\n","import math\n","from tqdm.notebook import tqdm\n","from torch.nn import CrossEntropyLoss\n","from typing import Tuple, List, Optional, Dict, Callable\n","from jaxtyping import Float, Int\n","from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n","from collections import defaultdict\n","from rich.table import Table\n","from rich import print as rprint\n","import datasets\n","from torch.utils.data import DataLoader\n","import wandb\n","from pathlib import Path\n","import webbrowser\n","import yaml"],"metadata":{"id":"mGulyEkJOLkl","executionInfo":{"status":"ok","timestamp":1710697120064,"user_tz":-60,"elapsed":266,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GiXQryesODEQ","executionInfo":{"status":"ok","timestamp":1710697099474,"user_tz":-60,"elapsed":7313,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}},"outputId":"bfe681ef-c80f-4eff-9abd-8fc919a4270f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n","\n","MAIN = __name__ == '__main__'\n","\n","reference_gpt2 = HookedTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"tBX2bmNoODES","executionInfo":{"status":"ok","timestamp":1710697099475,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["reference_text = \"Nikita and Danik are quite descent researchers\""]},{"cell_type":"code","execution_count":11,"metadata":{"id":"MnL3YqY4ODET","executionInfo":{"status":"ok","timestamp":1710697099845,"user_tz":-60,"elapsed":379,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["tokens = reference_gpt2.to_tokens(reference_text).to(device)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"236H35mQODEU","executionInfo":{"status":"ok","timestamp":1710697318208,"user_tz":-60,"elapsed":255,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["@dataclass\n","class Config:\n","    d_model: int = 768\n","    debug: bool = True\n","    layer_norm_eps: float = 1e-5\n","    d_vocab: int = 50257\n","    init_range: float = 0.02\n","    pos_embed: bool = True\n","    n_ctx: int = 1024\n","    d_head: int = 64\n","    d_mlp: int = 3072\n","    n_heads: int = 12\n","    n_layers: int = 12\n","\n","cfg = Config()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"-PAnDSW8ODEV","executionInfo":{"status":"ok","timestamp":1710697099847,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.w = nn.Parameter(t.ones(cfg.d_model))\n","        self.b = nn.Parameter(t.zeros(cfg.d_model))\n","\n","    def forward(self, residual: Float[Tensor, \"batch posn d_model\"]) -> Float[Tensor, \"batch posn d_model\"]:\n","\n","        residual_mean = residual.mean(dim=-1, keepdim=True)\n","        residual_std = (residual.var(dim=-1, keepdim=True, unbiased=False) + self.cfg.layer_norm_eps).sqrt()\n","\n","        residual = (residual - residual_mean) / residual_std\n","        return residual * self.w + self.b\n","\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Cwxo6o2nODEV","executionInfo":{"status":"ok","timestamp":1710697099847,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["class Embed(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n","        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n","\n","    def forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_model\"]:\n","\n","        return self.W_E[tokens]\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"wqO4F8CKODEX","executionInfo":{"status":"ok","timestamp":1710697142006,"user_tz":-60,"elapsed":424,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["class PosEmbed(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n","        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n","\n","    def forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_model\"]:\n","\n","        batch, seq_len = tokens.shape\n","        return einops.repeat(self.W_pos[:seq_len], \"seq d_model -> batch seq d_model\", batch=batch)\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"IdX1SoNJODEX","executionInfo":{"status":"ok","timestamp":1710697100752,"user_tz":-60,"elapsed":915,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["logits, cache = reference_gpt2.run_with_cache(tokens)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"uTNgqKWnODEY","executionInfo":{"status":"ok","timestamp":1710697101118,"user_tz":-60,"elapsed":382,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}},"outputId":"e6df2ce1-7ecb-4f6b-8c32-b2ce978fe1e8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<circuitsvis.utils.render.RenderedHTML at 0x79108440c5b0>"],"text/html":["<div id=\"circuits-vis-aab1a3b4-3d34\" style=\"margin: 15px 0;\"/>\n","    <script crossorigin type=\"module\">\n","    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n","    render(\n","      \"circuits-vis-aab1a3b4-3d34\",\n","      AttentionPatterns,\n","      {\"tokens\": [\"<|endoftext|>\", \"Nik\", \"ita\", \" and\", \" Dan\", \"ik\", \" are\", \" quite\", \" descent\", \" researchers\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9210671186447144, 0.07893288880586624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30190086364746094, 0.6682272553443909, 0.029871921986341476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6466350555419922, 0.11646536737680435, 0.19996201992034912, 0.03693750873208046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43304404616355896, 0.1216159537434578, 0.08789609372615814, 0.1566726118326187, 0.2007712721824646, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34519287943840027, 0.2126934826374054, 0.10042461007833481, 0.12845738232135773, 0.17280499637126923, 0.04042671248316765, 0.0, 0.0, 0.0, 0.0], [0.5270779728889465, 0.06601674854755402, 0.10844408720731735, 0.02578009106218815, 0.17088013887405396, 0.06585180014371872, 0.03594917058944702, 0.0, 0.0, 0.0], [0.4207213521003723, 0.19521914422512054, 0.05334460362792015, 0.07583615183830261, 0.05513307824730873, 0.055822473019361496, 0.07296308130025864, 0.07096012681722641, 0.0, 0.0], [0.29284828901290894, 0.13702505826950073, 0.04163040593266487, 0.1310722529888153, 0.051020629703998566, 0.07459952682256699, 0.039667367935180664, 0.07817046344280243, 0.15396592020988464, 0.0], [0.28123781085014343, 0.2835495173931122, 0.03683094680309296, 0.04286636784672737, 0.08367685228586197, 0.03430306166410446, 0.02436847798526287, 0.026353659108281136, 0.14006245136260986, 0.046750932931900024]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.1593580893531907e-05, 0.9999884366989136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.3948830857989378e-05, 0.00836145132780075, 0.991614580154419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001616748282685876, 0.0011639200383797288, 0.00030375411733984947, 0.9969155788421631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001811321562854573, 0.007499328814446926, 0.0005447436706162989, 0.00034973988658748567, 0.9914250373840332, 0.0, 0.0, 0.0, 0.0, 0.0], [1.781846185622271e-05, 0.0875573381781578, 0.0008477635565213859, 0.00022787628404330462, 0.0012437286786735058, 0.9101054668426514, 0.0, 0.0, 0.0, 0.0], [0.0006333948113024235, 0.0010241800919175148, 7.421848567901179e-05, 0.0058111632242798805, 0.00022647615696769208, 0.00023965448781382293, 0.991990864276886, 0.0, 0.0, 0.0], [3.288057996542193e-05, 0.00025259717949666083, 1.2827978935092688e-05, 0.00022452170378528535, 6.443847814807668e-05, 4.568387885228731e-05, 3.364354051882401e-05, 0.9993333220481873, 0.0, 0.0], [7.139994704630226e-05, 0.004045234993100166, 7.55280998419039e-05, 0.0005041994154453278, 0.0006089297821745276, 3.468940849415958e-05, 0.0002472617488820106, 0.0004169154854025692, 0.9939957857131958, 0.0], [0.0002441519172862172, 0.007136593572795391, 6.899762229295447e-05, 0.0004878050822298974, 0.0010228168684989214, 0.00022549479035660625, 0.0005079162074252963, 0.0005830355803482234, 0.0009299505618400872, 0.9887931942939758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792288541793823, 0.020771117880940437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9280314445495605, 0.041679054498672485, 0.030289461836218834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5246771574020386, 0.02309034764766693, 0.04442165046930313, 0.4078108072280884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7019132375717163, 0.10727489739656448, 0.06819913536310196, 0.05038480460643768, 0.07222791016101837, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6852335333824158, 0.050214335322380066, 0.09843594580888748, 0.06780225038528442, 0.06926336139440536, 0.029050633311271667, 0.0, 0.0, 0.0, 0.0], [0.5618897080421448, 0.05145532265305519, 0.033418942242860794, 0.11682939529418945, 0.07158643007278442, 0.024189112707972527, 0.14063102006912231, 0.0, 0.0, 0.0], [0.5879338383674622, 0.019236156716942787, 0.07338737696409225, 0.10118676722049713, 0.07309683412313461, 0.02457890287041664, 0.09105365723371506, 0.029526447877287865, 0.0, 0.0], [0.5326313972473145, 0.22500504553318024, 0.05861637741327286, 0.04576984792947769, 0.024460991844534874, 0.015410171821713448, 0.02895677462220192, 0.04689452052116394, 0.022254936397075653, 0.0], [0.5712453126907349, 0.04376111179590225, 0.09546257555484772, 0.033986348658800125, 0.02392720989882946, 0.03289841115474701, 0.037646982818841934, 0.024797169491648674, 0.058725327253341675, 0.07754955440759659]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05384649708867073, 0.946153461933136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013126062229275703, 0.7455885410308838, 0.24128533899784088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16473621129989624, 0.04815179109573364, 0.009988821111619473, 0.7771230936050415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011549534276127815, 0.01372511312365532, 0.0004944344982504845, 0.0008868311415426433, 0.9733440279960632, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002735529560595751, 0.010766695253551006, 0.0002313037111889571, 0.0001080797374015674, 0.001465709414333105, 0.9871547222137451, 0.0, 0.0, 0.0, 0.0], [0.028520256280899048, 0.002921873005107045, 0.0002268550597364083, 0.010401180014014244, 0.004641527310013771, 0.005665570963174105, 0.9476227760314941, 0.0, 0.0, 0.0], [0.0002658357552718371, 0.0001031713472912088, 1.3479013432515785e-05, 6.598245090572163e-05, 3.611335705500096e-05, 0.000374141673091799, 0.0006757888477295637, 0.9984655380249023, 0.0, 0.0], [0.0040994323790073395, 0.0005723178619518876, 0.000269578886218369, 4.657708268496208e-05, 0.0017408269923180342, 0.00032124854624271393, 0.00033743237145245075, 0.0005731641431339085, 0.9920395612716675, 0.0], [0.00723576545715332, 0.001066496130079031, 0.00019054650329053402, 6.638695776928216e-05, 0.004516864661127329, 0.00013859976024832577, 0.00033847728627733886, 0.0033768252469599247, 0.020832287147641182, 0.9622377753257751]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06472159922122955, 0.9352783560752869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02245090715587139, 0.7781036496162415, 0.19944538176059723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.394636332988739, 0.13748908042907715, 0.1177959144115448, 0.35007864236831665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06571973860263824, 0.01993522047996521, 0.0032419245690107346, 0.003943377174437046, 0.9071597456932068, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00766213471069932, 0.45186299085617065, 0.012612233869731426, 0.005671526771038771, 0.2026592195034027, 0.3195318877696991, 0.0, 0.0, 0.0, 0.0], [0.18682202696800232, 0.05958142876625061, 0.020068712532520294, 0.08928132802248001, 0.14769697189331055, 0.0674276128411293, 0.4291219413280487, 0.0, 0.0, 0.0], [0.022432250902056694, 0.0037724042776972055, 0.0043440465815365314, 0.024175141006708145, 0.009371742606163025, 0.006345536559820175, 0.24738028645515442, 0.6821785569190979, 0.0, 0.0], [0.04125161096453667, 0.01646755263209343, 0.007373906206339598, 0.003037363523617387, 0.007685908116400242, 0.005931483116000891, 0.0035626778844743967, 0.008925563655793667, 0.9057638645172119, 0.0], [0.053320061415433884, 0.0051375944167375565, 0.006527331657707691, 0.006379507947713137, 0.09270396828651428, 0.006402501370757818, 0.01197521761059761, 0.05636567249894142, 0.10263048857450485, 0.6585575938224792]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14669501781463623, 0.853304922580719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012021838687360287, 0.00021780656243208796, 0.9877603650093079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3659180998802185, 0.003915625158697367, 0.011062322184443474, 0.6191039681434631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08108215034008026, 5.191154923522845e-05, 0.00017646500782575458, 1.3997771020513028e-05, 0.9186755418777466, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00691495556384325, 0.00022412191901821643, 0.0001488322450313717, 9.445333262192435e-07, 1.0468364962434862e-05, 0.9927005767822266, 0.0, 0.0, 0.0, 0.0], [0.08355817198753357, 0.0001870901178335771, 0.0013904623920097947, 0.0018739831866696477, 0.00010526489495532587, 0.003938709385693073, 0.9089463949203491, 0.0, 0.0, 0.0], [0.00903353188186884, 0.00034172480809502304, 1.2810922271455638e-05, 2.7090272851637565e-05, 2.3125088773667812e-05, 0.00013004049833398312, 1.8630282738740789e-06, 0.9904298186302185, 0.0, 0.0], [0.004871336743235588, 4.155333590460941e-05, 4.936479854222853e-06, 1.9313722532388056e-07, 2.2807153072790243e-06, 1.5889376072664163e-06, 1.3982523228150967e-07, 1.3600601960206404e-06, 0.995076596736908, 0.0], [0.0036165332421660423, 0.000888292386662215, 8.010913916223217e-06, 3.2284399367199512e-06, 0.00043457976425997913, 3.8595338992308825e-05, 2.133522457370418e-06, 7.60050306780613e-06, 0.00019732009968720376, 0.9948038458824158]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9397050738334656, 0.060294996947050095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18354782462120056, 0.7452970743179321, 0.0711551085114479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4509696960449219, 0.4070607125759125, 0.11924883723258972, 0.022720739245414734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3953949809074402, 0.2633092701435089, 0.09339671581983566, 0.0644189640879631, 0.18348008394241333, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21539394557476044, 0.5726832151412964, 0.07539398968219757, 0.024800850078463554, 0.05269579589366913, 0.05903215333819389, 0.0, 0.0, 0.0, 0.0], [0.28097715973854065, 0.2618887424468994, 0.09537647664546967, 0.026420116424560547, 0.20378446578979492, 0.08927962183952332, 0.04227336868643761, 0.0, 0.0, 0.0], [0.18261408805847168, 0.1531166285276413, 0.04263043776154518, 0.037737976759672165, 0.08688049763441086, 0.04969893395900726, 0.05265824869275093, 0.3946632444858551, 0.0, 0.0], [0.238298699259758, 0.23632079362869263, 0.10999947786331177, 0.05169236660003662, 0.11820685118436813, 0.043951403349637985, 0.020891249179840088, 0.04529288783669472, 0.13534626364707947, 0.0], [0.35568276047706604, 0.15506234765052795, 0.05071759596467018, 0.023865902796387672, 0.039064258337020874, 0.03363293781876564, 0.015245628543198109, 0.03357397019863129, 0.1354186236858368, 0.1577359437942505]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9625491499900818, 0.03745080903172493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32909631729125977, 0.6260460615158081, 0.04485763609409332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3460356295108795, 0.1576465517282486, 0.20149728655815125, 0.29482054710388184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2869870364665985, 0.10539361834526062, 0.1070638969540596, 0.37672269344329834, 0.12383270263671875, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12532994151115417, 0.07817518711090088, 0.09401531517505646, 0.16514284908771515, 0.4851492941379547, 0.052187394350767136, 0.0, 0.0, 0.0, 0.0], [0.18534237146377563, 0.0514758862555027, 0.01728222519159317, 0.15471577644348145, 0.1625424176454544, 0.13340330123901367, 0.29523807764053345, 0.0, 0.0, 0.0], [0.13087433576583862, 0.13233770430088043, 0.02002754434943199, 0.11526985466480255, 0.03639741614460945, 0.03385685756802559, 0.38555988669395447, 0.14567643404006958, 0.0, 0.0], [0.18662148714065552, 0.0074393171817064285, 0.018638812005519867, 0.12664085626602173, 0.007307850290089846, 0.017122311517596245, 0.35321205854415894, 0.16633014380931854, 0.11668711155653, 0.0], [0.13581912219524384, 0.014423973858356476, 0.012550854124128819, 0.08772307634353638, 0.02455611526966095, 0.014022957533597946, 0.20153360068798065, 0.14652928709983826, 0.20885470509529114, 0.15398633480072021]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8879808187484741, 0.11201925575733185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8148980736732483, 0.14012554287910461, 0.0449763759970665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24233365058898926, 0.038320355117321014, 0.04189502075314522, 0.677450954914093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4898678660392761, 0.11550116539001465, 0.08922205120325089, 0.16547340154647827, 0.13993556797504425, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3533780872821808, 0.2536996304988861, 0.10195797681808472, 0.12134572118520737, 0.13547788560390472, 0.03414071723818779, 0.0, 0.0, 0.0, 0.0], [0.14384518563747406, 0.02464871294796467, 0.03258334845304489, 0.35756340622901917, 0.04712854325771332, 0.02753961831331253, 0.3666911721229553, 0.0, 0.0, 0.0], [0.22458839416503906, 0.025762885808944702, 0.04460261017084122, 0.25041672587394714, 0.04586632177233696, 0.04608122259378433, 0.2923937737941742, 0.07028800994157791, 0.0, 0.0], [0.4272739887237549, 0.06937883049249649, 0.07779694348573685, 0.12203910946846008, 0.022647492587566376, 0.0497952476143837, 0.047504864633083344, 0.0845145583152771, 0.09904895722866058, 0.0], [0.42888739705085754, 0.0578538179397583, 0.0542035736143589, 0.12451833486557007, 0.06065686419606209, 0.02281269058585167, 0.08681097626686096, 0.09437989443540573, 0.02929764613509178, 0.040578775107860565]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9870604276657104, 0.012939570471644402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8174858093261719, 0.14344340562820435, 0.03907083347439766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6849213242530823, 0.05915815383195877, 0.08272450417280197, 0.17319609224796295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6623350977897644, 0.08220482617616653, 0.10355336964130402, 0.1311357319355011, 0.020771030336618423, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5492441654205322, 0.10480890423059464, 0.08283641934394836, 0.1404397040605545, 0.08739341050386429, 0.0352773480117321, 0.0, 0.0, 0.0, 0.0], [0.48027467727661133, 0.04888617619872093, 0.07638919353485107, 0.15337717533111572, 0.07326722890138626, 0.046548184007406235, 0.12125744670629501, 0.0, 0.0, 0.0], [0.5048245191574097, 0.04758977144956589, 0.05571002513170242, 0.12206877768039703, 0.07115353643894196, 0.033964235335588455, 0.10235407203435898, 0.06233504042029381, 0.0, 0.0], [0.5214108824729919, 0.07155163586139679, 0.06998909264802933, 0.09838075935840607, 0.04910529777407646, 0.046023279428482056, 0.06817911565303802, 0.06316359341144562, 0.012196309864521027, 0.0], [0.5081335306167603, 0.06224793195724487, 0.0536198690533638, 0.08671730756759644, 0.04229562357068062, 0.030169419944286346, 0.0631331279873848, 0.06340273469686508, 0.06404827535152435, 0.026232236996293068]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7499335408210754, 0.2500664293766022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6514663696289062, 0.08827376365661621, 0.2602598965167999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.690597414970398, 0.055678848177194595, 0.05851861461997032, 0.19520507752895355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4675404131412506, 0.09283585846424103, 0.06336020678281784, 0.12862573564052582, 0.24763792753219604, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3930817246437073, 0.14002303779125214, 0.08247900009155273, 0.10420341044664383, 0.046309664845466614, 0.23390308022499084, 0.0, 0.0, 0.0, 0.0], [0.378905326128006, 0.04447788745164871, 0.05790599808096886, 0.160329669713974, 0.0421358160674572, 0.03656535968184471, 0.27967992424964905, 0.0, 0.0, 0.0], [0.3710286617279053, 0.05044716224074364, 0.03239915147423744, 0.14294776320457458, 0.041671011596918106, 0.026827890425920486, 0.06275076419115067, 0.2719276249408722, 0.0, 0.0], [0.3213804066181183, 0.06025252863764763, 0.04595929756760597, 0.1099652424454689, 0.031850770115852356, 0.024654528126120567, 0.05028097704052925, 0.04941447824239731, 0.30624181032180786, 0.0], [0.3047509789466858, 0.06410081684589386, 0.033968228846788406, 0.09864052385091782, 0.03614044189453125, 0.022807680070400238, 0.058212701231241226, 0.04389224946498871, 0.03308481350541115, 0.30440154671669006]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8246960043907166, 0.17530399560928345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5612883567810059, 0.3846740126609802, 0.05403759703040123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5872053503990173, 0.1608920693397522, 0.029597045853734016, 0.2223055362701416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38262301683425903, 0.4103069007396698, 0.029075991362333298, 0.1316065788269043, 0.04638750106096268, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5249226093292236, 0.2113991677761078, 0.05115678161382675, 0.12783284485340118, 0.05655910447239876, 0.02812938205897808, 0.0, 0.0, 0.0, 0.0], [0.5157449245452881, 0.14761792123317719, 0.01999950222671032, 0.1470620483160019, 0.03376910835504532, 0.017210792750120163, 0.11859574913978577, 0.0, 0.0, 0.0], [0.5033628344535828, 0.13205890357494354, 0.024730652570724487, 0.10735104233026505, 0.036869507282972336, 0.01769295334815979, 0.05927884206175804, 0.11865533888339996, 0.0, 0.0], [0.33180150389671326, 0.1320129632949829, 0.01505476888269186, 0.11077088117599487, 0.05111062154173851, 0.020288849249482155, 0.07003150135278702, 0.11642321199178696, 0.1525057554244995, 0.0], [0.3261103332042694, 0.1606547087430954, 0.01712857000529766, 0.09446481615304947, 0.029143447056412697, 0.014018836431205273, 0.11476819217205048, 0.08614526689052582, 0.07728014886379242, 0.0802856907248497]]]}\n","    )\n","    </script>"]},"metadata":{}}],"source":["import circuitsvis as cv\n","from IPython.display import display\n","\n","html = cv.attention.attention_patterns(\n","    tokens=reference_gpt2.to_str_tokens(reference_text),\n","    attention=cache[\"pattern\", 0][0]\n",")\n","display(html)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"xqXt4mPiODEa","executionInfo":{"status":"ok","timestamp":1710697101119,"user_tz":-60,"elapsed":17,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["class Attention(nn.Module):\n","    IGNORE: Float[Tensor, \"\"]\n","\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n","        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n","        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n","        self.register_buffer(\"IGNORE\", t.tensor(-1e5, dtype=t.float32, device=device))\n","\n","    def forward(\n","        self, normalized_resid_pre: Float[Tensor, \"batch posn d_model\"]\n","    ) -> Float[Tensor, \"batch posn d_model\"]:\n","\n","        # Calculate query, key and value vectors\n","        q = einops.einsum(\n","            normalized_resid_pre, self.W_Q,\n","            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n","        ) + self.b_Q\n","        k = einops.einsum(\n","            normalized_resid_pre, self.W_K,\n","            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n","        ) + self.b_K\n","        v = einops.einsum(\n","            normalized_resid_pre, self.W_V,\n","            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n","        ) + self.b_V\n","\n","        # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n","        attn_scores = einops.einsum(\n","            q, k,\n","            \"batch posn_Q nheads d_head, batch posn_K nheads d_head -> batch nheads posn_Q posn_K\",\n","        )\n","        attn_scores_masked = self.apply_causal_mask(attn_scores / self.cfg.d_head ** 0.5)\n","        attn_pattern = attn_scores_masked.softmax(-1)\n","\n","        # Take weighted sum of value vectors, according to attention probabilities\n","        z = einops.einsum(\n","            v, attn_pattern,\n","            \"batch posn_K nheads d_head, batch nheads posn_Q posn_K -> batch posn_Q nheads d_head\",\n","        )\n","\n","        # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n","        attn_out = einops.einsum(\n","            z, self.W_O,\n","            \"batch posn_Q nheads d_head, nheads d_head d_model -> batch posn_Q d_model\",\n","        ) + self.b_O\n","\n","        return attn_out\n","\n","    def apply_causal_mask(\n","        self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"]\n","    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n","        '''\n","        Applies a causal mask to attention scores, and returns masked scores.\n","        '''\n","\n","        # Define a mask that is True for all positions we want to set probabilities to zero for\n","        all_ones = t.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device)\n","        mask = t.triu(all_ones, diagonal=1).bool()\n","        # Apply the mask to attention scores, then return the masked scores\n","        attn_scores.masked_fill_(mask, self.IGNORE)\n","        return attn_scores\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"fb4DcDb8ODEb","executionInfo":{"status":"ok","timestamp":1710697101120,"user_tz":-60,"elapsed":16,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n","        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n","        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n","        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n","        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n","\n","    def forward(\n","        self, normalized_resid_mid: Float[Tensor, \"batch posn d_model\"]\n","    ) -> Float[Tensor, \"batch posn d_model\"]:\n","\n","        pre = einops.einsum(\n","            normalized_resid_mid, self.W_in,\n","            \"batch position d_model, d_model d_mlp -> batch position d_mlp\",\n","        ) + self.b_in\n","        post = gelu_new(pre)\n","        mlp_out = einops.einsum(\n","            post, self.W_out,\n","            \"batch position d_mlp, d_mlp d_model -> batch position d_model\",\n","        ) + self.b_out\n","        return mlp_out"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"i_nrGFKeODEc","executionInfo":{"status":"ok","timestamp":1710697101351,"user_tz":-60,"elapsed":245,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.ln1 = LayerNorm(cfg)\n","        self.attn = Attention(cfg)\n","        self.ln2 = LayerNorm(cfg)\n","        self.mlp = MLP(cfg)\n","\n","    def forward(\n","        self, resid_pre: Float[Tensor, \"batch position d_model\"]\n","    ) -> Float[Tensor, \"batch position d_model\"]:\n","\n","        resid_mid = self.attn(self.ln1(resid_pre)) + resid_pre\n","        resid_post = self.mlp(self.ln2(resid_mid)) + resid_mid\n","        return resid_post\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"qGDajQgBODEd","executionInfo":{"status":"ok","timestamp":1710697101352,"user_tz":-60,"elapsed":14,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["class Unembed(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n","        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n","        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n","\n","    def forward(\n","        self, normalized_resid_final: Float[Tensor, \"batch position d_model\"]\n","    ) -> Float[Tensor, \"batch position d_vocab\"]:\n","\n","        return einops.einsum(\n","            normalized_resid_final, self.W_U,\n","            \"batch posn d_model, d_model d_vocab -> batch posn d_vocab\",\n","        ) + self.b_U\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"HTtNOkP8ODEe","executionInfo":{"status":"ok","timestamp":1710697259867,"user_tz":-60,"elapsed":258,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["class DemoTransformer(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.embed = Embed(cfg)\n","        if cfg.pos_embed:\n","            self.pos_embed = PosEmbed(cfg)\n","        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n","        self.ln_final = LayerNorm(cfg)\n","        self.unembed = Unembed(cfg)\n","\n","    def forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_vocab\"]:\n","        # SOLUTION\n","        residual = self.embed(tokens)\n","        if self.cfg.pos_embed:\n","          residual += self.pos_embed(tokens)\n","        for block in self.blocks:\n","            residual = block(residual)\n","        logits = self.unembed(self.ln_final(residual))\n","        return logits"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"e7v_81QDODEe","executionInfo":{"status":"ok","timestamp":1710697101353,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["def get_log_probs(\n","    logits: Float[Tensor, \"batch posn d_vocab\"],\n","    tokens: Int[Tensor, \"batch posn\"]\n",") -> Float[Tensor, \"batch posn-1\"]:\n","\n","    log_probs = logits.log_softmax(dim=-1)\n","    # Get logprobs the first seq_len-1 predictions (so we can compare them with the actual next tokens)\n","    log_probs_for_tokens = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n","\n","    return log_probs_for_tokens\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"-32S6EJVODEf","executionInfo":{"status":"ok","timestamp":1710697330463,"user_tz":-60,"elapsed":1339,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["model_cfg = Config(\n","    debug=False,\n","    d_model=256,\n","    n_heads=4,\n","    d_head=64,\n","    d_mlp=1024,\n","    n_layers=2,\n","    n_ctx=256,\n","    pos_embed=False,\n","    d_vocab=reference_gpt2.cfg.d_vocab\n",")\n","\n","model = DemoTransformer(model_cfg).to(device)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Dvr_t-09ODEf","executionInfo":{"status":"ok","timestamp":1710697334743,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"outputs":[],"source":["@dataclass\n","class TransformerTrainingArgs():\n","\t\tbatch_size = 16\n","\t\tepochs = 20\n","\t\tmax_steps_per_epoch = 200\n","\t\tlr = 1e-3\n","\t\tweight_decay = 1e-2\n","\t\tfrac_train=0.3\n","\t\tseed=42\n","\t\tp=113\n","\t\tstopping_thresh=3e-6\n","\t\tsave_models = False\n","\t\tsave_every = 100\n","\t\tbetas=(0.9, 0.98)\n","\t\twandb_project: Optional[str] = \"day1-demotransformer\"\n","\t\twandb_name: Optional[str] = None\n","\n","\n","args = TransformerTrainingArgs()"]},{"cell_type":"code","source":["import random\n","\n","# train and test datasets for the sum mod task\n","def generate_train_test(frac_train, num, seed=0):\n","    # Generate train and test split\n","    dataset = [(i, j, num) for i in range(num) for j in range(num)]\n","    random.seed(seed)\n","    random.shuffle(dataset)\n","    threshold = int(frac_train*len(dataset))\n","    return t.tensor(dataset[:threshold]).to(device), t.tensor(dataset[threshold:]).to(device)"],"metadata":{"id":"C3PXBitXQZMc","executionInfo":{"status":"ok","timestamp":1710697336534,"user_tz":-60,"elapsed":375,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["train_dataset, test_dataset = generate_train_test(args.frac_train, args.p, args.seed)\n","print(len(train_dataset), len(test_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csWgWjyhROfp","executionInfo":{"status":"ok","timestamp":1710697338290,"user_tz":-60,"elapsed":483,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}},"outputId":"7b818bc5-acd9-48a7-84b5-bcf1ebbaaf89"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["3830 8939\n"]}]},{"cell_type":"code","source":["def lines(lines_list, x=None, mode='lines', labels=None, xaxis='', yaxis='', title = '', log_y=False, hover=None, **kwargs):\n","    # Helper function to plot multiple lines\n","    if type(lines_list)==t.Tensor:\n","        lines_list = [lines_list[i] for i in range(lines_list.shape[0])]\n","    if x is None:\n","        x=np.arange(len(lines_list[0]))\n","    fig = go.Figure(layout={'title':title})\n","    fig.update_xaxes(title=xaxis)\n","    fig.update_yaxes(title=yaxis)\n","    for c, line in enumerate(lines_list):\n","        if type(line)==t.Tensor:\n","            line = np.array(line.tolist())\n","        if labels is not None:\n","            label = labels[c]\n","        else:\n","            label = c\n","        fig.add_trace(go.Scatter(x=x, y=line, mode=mode, name=label, hovertext=hover, **kwargs))\n","    if log_y:\n","        fig.update_layout(yaxis_type=\"log\")\n","    fig.show()"],"metadata":{"id":"5Hq7btoacK4V","executionInfo":{"status":"ok","timestamp":1710697338713,"user_tz":-60,"elapsed":426,"user":{"displayName":"Daniil Yurshewich","userId":"06547323051303617288"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def train_loop(model, args):\n","    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay, betas=(0.9, 0.98))\n","    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(step/10, 1))\n","    run_name = f\"grok_{int(time.time())}\"\n","    loss=CrossEntropyLoss()\n","    print(f'Run name {run_name}')\n","    if args.save_models:\n","        os.mkdir(run_name)\n","        save_dict = {'model':model.state_dict(), 'train_data':train_dataset, 'test_data':test_dataset}\n","        t.save(save_dict, f'{run_name}/init.pth')\n","    train_losses = []\n","    test_losses = []\n","    for epoch in range(args.epochs):\n","        pred=model(train_dataset)[:, -1]\n","        labels=t.tensor([i+j % args.p for (i, j, _) in train_dataset]).to(device)\n","        train_loss = loss(pred, labels)\n","\n","        pred=model(test_dataset)[:, -1]\n","        labels=t.tensor([i+j % args.p for (i, j, _) in test_dataset]).to(device)\n","        test_loss = loss(pred, labels)\n","\n","        train_losses.append(train_loss.item())\n","        test_losses.append(test_loss.item())\n","\n","        if epoch%100 == 0: print(f\"{epoch}_{np.log(train_loss.item()):.4f}_{np.log(test_loss.item()):.4f}\")#_{train_acc.item():.4f}_{test_acc.item():.4f}\")\n","        train_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        if test_loss.item() < args.stopping_thresh:\n","            break\n","        if (args.save_models) and (epoch%args.save_every == 0):\n","            if test_loss.item() < args.stopping_thresh:\n","                break\n","            save_dict = {\n","                'model': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'scheduler': scheduler.state_dict(),\n","                'train_loss': train_loss,\n","                'test_loss': test_loss,\n","                'epoch': epoch,\n","            }\n","            t.save(save_dict, f'/{run_name}/{epoch}.pth')\n","            print(f\"Saved model to /{run_name}/{epoch}.pth\")\n","    if not args.save_models:\n","        os.mkdir(f'{run_name}')\n","    save_dict = {\n","        'model': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        'scheduler': scheduler.state_dict(),\n","        'train_loss': train_loss,\n","        'test_loss': test_loss,\n","        'train_losses': train_losses,\n","        'test_losses': test_losses,\n","        'epoch': epoch,\n","    }\n","    t.save(save_dict, f'{run_name}/final.pth')\n","    print(f\"Saved model to {run_name}/final.pth\")\n","    lines([train_losses, test_losses], labels=['train', 'test'], log_y=True)\n","\n","    # save_models = False\n","\n","train_loop(model, args)"],"metadata":{"id":"jAWnD_CwVHok","colab":{"base_uri":"https://localhost:8080/"},"outputId":"39b0e537-d6d2-403b-f456-a3b16681456c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Run name grok_1710700941\n","hui\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}